{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is inspired by: \n",
    "\n",
    "- https://www.kaggle.com/code/carlmcbrideellis/an-introduction-to-xgboost-regression\n",
    "- https://www.kaggle.com/code/dansbecker/xgboost/notebook\n",
    "\n",
    "In this assignment we will apply XGBoost Regression techniques to predict house prices, based on the famous Kaggle Dataset https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques\n",
    "\n",
    "Step 1 is to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "e7842527-0531-44fa-8ce0-ae4cc3cfd0d7",
    "_uuid": "365f3e96-c7a9-41cf-9c5f-76dbfd46168c",
    "execution": {
     "iopub.execute_input": "2022-10-17T08:49:03.875064Z",
     "iopub.status.busy": "2022-10-17T08:49:03.874451Z",
     "iopub.status.idle": "2022-10-17T08:49:03.951957Z",
     "shell.execute_reply": "2022-10-17T08:49:03.950940Z",
     "shell.execute_reply.started": "2022-10-17T08:49:03.874981Z"
    }
   },
   "outputs": [],
   "source": [
    "#=========================================================================\n",
    "# load up the libraries\n",
    "#=========================================================================\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "import xgboost as xgb\n",
    "\n",
    "#=========================================================================\n",
    "# read in the data\n",
    "#=========================================================================\n",
    "train_data = pd.read_csv('data/train.csv',index_col=0)\n",
    "test_data  = pd.read_csv('data/test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center style=\"background-color:Gainsboro; width:60%;\">Feature selection</center>\n",
    "The purpose of feature selection, as the name suggests, is to only model the most pertinent and important features, thus reducing the computational overhead, and also to alleviate the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality). The following are a number of notebooks covering techniques to achieve said goal, all of which use the House Prices data as an example:\n",
    "\n",
    "* [Feature selection using the Boruta-SHAP package](https://www.kaggle.com/carlmcbrideellis/feature-selection-using-the-boruta-shap-package)\n",
    "* [Recursive Feature Elimination (RFE) example](https://www.kaggle.com/carlmcbrideellis/recursive-feature-elimination-rfe-example)\n",
    "* [House Prices: Permutation Importance example](https://www.kaggle.com/carlmcbrideellis/house-prices-permutation-importance-example)\n",
    "* [Feature importance using the LASSO](https://www.kaggle.com/carlmcbrideellis/feature-importance-using-the-lasso)\n",
    "\n",
    "In this assignment, we shall use all of the numerical columns, and ignore the categorical features. To encode the categorical features one can use for example [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html). \n",
    "\n",
    "Our first task is to do Feature Exploration and Selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.select_dtypes(include=['number']).copy()\n",
    "X_train = X_train.drop(['SalePrice'], axis=1)\n",
    "y_train = train_data[\"SalePrice\"]\n",
    "X_test  = test_data.select_dtypes(include=['number']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center style=\"background-color:Gainsboro; width:60%;\">Feature engineering</center>\n",
    "As mentioned, one aspect of feature engineering is the creation of new features out of existing features. A simple example would be to create a new feature which is the sum of the number of bathrooms in the house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T08:49:03.999750Z",
     "iopub.status.busy": "2022-10-17T08:49:03.999440Z",
     "iopub.status.idle": "2022-10-17T08:49:04.014461Z",
     "shell.execute_reply": "2022-10-17T08:49:04.013575Z",
     "shell.execute_reply.started": "2022-10-17T08:49:03.999715Z"
    }
   },
   "outputs": [],
   "source": [
    "for df in (X_train, X_test):\n",
    "    df[\"n_bathrooms\"] = df[\"BsmtFullBath\"] + (df[\"BsmtHalfBath\"]*0.5) + df[\"FullBath\"] + (df[\"HalfBath\"]*0.5)\n",
    "    df[\"area_with_basement\"]  = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on this fascinating aspect may I recommend the free on-line book [\"*Feature Engineering and Selection: A Practical Approach for Predictive Models*\"](http://www.feat.engineering/) by Max Kuhn and Kjell Johnson.\n",
    "### <center style=\"background-color:Gainsboro; width:60%;\">XGBoost estimator</center>\n",
    "Note that for this competition we use the RMSLE evaluation metric, rather than the default metric, which for regression is the RMSE. For more on the peculiarities of the RMSLE see the Appendix below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_cell_guid": "e7842527-0531-44fa-8ce0-ae4cc3cfd0d7",
    "_uuid": "365f3e96-c7a9-41cf-9c5f-76dbfd46168c",
    "execution": {
     "iopub.execute_input": "2022-10-17T08:49:04.016433Z",
     "iopub.status.busy": "2022-10-17T08:49:04.015704Z",
     "iopub.status.idle": "2022-10-17T08:50:04.782101Z",
     "shell.execute_reply": "2022-10-17T08:50:04.781125Z",
     "shell.execute_reply.started": "2022-10-17T08:49:04.016384Z"
    }
   },
   "outputs": [],
   "source": [
    "#=========================================================================\n",
    "# XGBoost regression: \n",
    "# Parameters: \n",
    "# n_estimators  \"Number of gradient boosted trees. Equivalent to number \n",
    "#                of boosting rounds.\"\n",
    "# learning_rate \"Boosting learning rate (also known as “eta”)\"\n",
    "# max_depth     \"Maximum depth of a tree. Increasing this value will make \n",
    "#                the model more complex and more likely to overfit.\" \n",
    "#=========================================================================\n",
    "regressor=xgb.XGBRegressor(eval_metric='rmsle')\n",
    "\n",
    "#=========================================================================\n",
    "# exhaustively search for the optimal hyperparameters\n",
    "#=========================================================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# set up our search grid\n",
    "param_grid = {\"max_depth\":    [4, 5],\n",
    "              \"n_estimators\": [500, 600, 700],\n",
    "              \"learning_rate\": [0.01, 0.015]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you use grid search to find the optimal hyper parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put code here\n",
    "search = GridSearchCV(regressor, param_grid, cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters are  {'learning_rate': 0.015, 'max_depth': 4, 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters are \",search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you setup a XGBoost Regressor object using your hyperparameters and fit it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "e7842527-0531-44fa-8ce0-ae4cc3cfd0d7",
    "_uuid": "365f3e96-c7a9-41cf-9c5f-76dbfd46168c",
    "execution": {
     "iopub.execute_input": "2022-10-17T08:51:42.696134Z",
     "iopub.status.busy": "2022-10-17T08:51:42.695498Z",
     "iopub.status.idle": "2022-10-17T08:51:43.901785Z",
     "shell.execute_reply": "2022-10-17T08:51:43.900931Z",
     "shell.execute_reply.started": "2022-10-17T08:51:42.696091Z"
    }
   },
   "outputs": [],
   "source": [
    "# put code here\n",
    "regressor=xgb.XGBRegressor(learning_rate = search.best_params_[\"learning_rate\"],\n",
    "                           n_estimators  = search.best_params_[\"n_estimators\"],\n",
    "                           max_depth     = search.best_params_[\"max_depth\"],\n",
    "                           eval_metric='rmsle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmsle&#x27;, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.015, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmsle&#x27;, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.015, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='rmsle', feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.015, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, can you run it on your test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can you score your solution offline and see how it does?\n",
    "solution = pd.DataFrame({\"id\":test_data.index, \"SalePrice\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.to_csv(\"data/solution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.to_numpy of       Unnamed: 0    id   SalePrice\n",
       "0              0  1461  128655.090\n",
       "1              1  1462  158067.230\n",
       "2              2  1463  186815.380\n",
       "3              3  1464  187704.950\n",
       "4              4  1465  178389.880\n",
       "...          ...   ...         ...\n",
       "1454        1454  2915   82225.336\n",
       "1455        1455  2916   88845.480\n",
       "1456        1456  2917  180738.020\n",
       "1457        1457  2918  123743.080\n",
       "1458        1458  2919  226034.880\n",
       "\n",
       "[1459 rows x 3 columns]>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m solution \u001b[39m=\u001b[39m solution\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mUnnamed: 0\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.10/site-packages/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5266\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.10/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.10/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/test_env/lib/python3.10/site-packages/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "solution = solution.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.00000\n"
     ]
    }
   ],
   "source": [
    "# read in the ground truth file\n",
    "solution   = pd.read_csv(\"data/solution.csv\")\n",
    "y_true     = solution[\"SalePrice\"]\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "RMSLE = np.sqrt( mean_squared_log_error(y_true, predictions) )\n",
    "print(\"The score is %.5f\" % RMSLE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the below block to prepare your submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e7842527-0531-44fa-8ce0-ae4cc3cfd0d7",
    "_uuid": "365f3e96-c7a9-41cf-9c5f-76dbfd46168c",
    "execution": {
     "iopub.execute_input": "2022-10-17T08:50:06.964744Z",
     "iopub.status.busy": "2022-10-17T08:50:06.964340Z",
     "iopub.status.idle": "2022-10-17T08:50:06.977852Z",
     "shell.execute_reply": "2022-10-17T08:50:06.976712Z",
     "shell.execute_reply.started": "2022-10-17T08:50:06.964712Z"
    }
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"Id\":test_data.index, \"SalePrice\":predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center style=\"background-color:Gainsboro; width:60%;\">Feature importance</center>\n",
    "Let us also take a very quick look at the feature importance too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T08:50:06.980369Z",
     "iopub.status.busy": "2022-10-17T08:50:06.979530Z",
     "iopub.status.idle": "2022-10-17T08:50:07.282871Z",
     "shell.execute_reply": "2022-10-17T08:50:07.281929Z",
     "shell.execute_reply.started": "2022-10-17T08:50:06.980309Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plot_importance(regressor, max_num_features=8, ax=ax)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where here the `F score` is a measure \"*...based on the number of times a variable is selected for splitting, weighted by the squared improvement to the model as a result of each split, and averaged over all trees*.\" [1] \n",
    "\n",
    "Note that these importances are susceptible to small changes in the training data, and it is much better to make use of [\"GPU accelerated SHAP values\"](https://www.kaggle.com/carlmcbrideellis/gpu-accelerated-shap-values-jane-street-example), incorporated with version 1.3 of XGBoost.\n",
    "\n",
    "Can you follow the above guide use SHAP values instead of F Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center style=\"background-color:Gainsboro; width:60%;\">Appendix: The RMSLE evaluation metric</center>\n",
    "From the competition [evaluation page](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) we see that the metric we are using is the root mean squared logarithmic error (RMSLE), which is given by\n",
    "\n",
    "$$ {\\mathrm {RMSLE}}\\,(y, \\hat y) = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\hat{y}_i) - \\log (1 + y_i)\\right)^2} $$\n",
    "\n",
    "where $\\hat{y}_i$ is the predicted value of the target for instance $i$, and $y_i$\n",
    "is the actual value of the target for instance $i$.\n",
    "\n",
    "It is important to note that, unlike the RMSE, the RMSLE is asymmetric; penalizing much more the underestimated predictions than the overestimated predictions. For example, say the correct value is $y_i = 1000$, then underestimating by 600 is almost twice as bad as overestimating by 600:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T08:50:07.284616Z",
     "iopub.status.busy": "2022-10-17T08:50:07.284340Z",
     "iopub.status.idle": "2022-10-17T08:50:07.290854Z",
     "shell.execute_reply": "2022-10-17T08:50:07.289987Z",
     "shell.execute_reply.started": "2022-10-17T08:50:07.284584Z"
    }
   },
   "outputs": [],
   "source": [
    "def RSLE(y_hat,y):\n",
    "    return np.sqrt((np.log1p(y_hat) - np.log1p(y))**2)\n",
    "\n",
    "print(\"The RMSLE score is %.3f\" % RSLE( 400,1000) )\n",
    "print(\"The RMSLE score is %.3f\" % RSLE(1600,1000) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asymmetry arises because \n",
    "\n",
    "$$ \\log (1 + \\hat{y}_i) - \\log (1 + y_i) =  \\log \\left( \\frac{1 + \\hat{y}_i}{1 + y_i} \\right) $$\n",
    "\n",
    "so we are essentially looking at ratios, rather than differences such as is the case of the RMSE. We can see the form that this asymmetry takes in the following plot, again using 1000 as our ground truth value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T08:50:07.292446Z",
     "iopub.status.busy": "2022-10-17T08:50:07.292191Z",
     "iopub.status.idle": "2022-10-17T08:50:07.467273Z",
     "shell.execute_reply": "2022-10-17T08:50:07.466163Z",
     "shell.execute_reply.started": "2022-10-17T08:50:07.292407Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (7, 4)\n",
    "x = np.linspace(5,4000,100)\n",
    "plt.plot(x, RSLE(x,1000))\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('RMSLE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
